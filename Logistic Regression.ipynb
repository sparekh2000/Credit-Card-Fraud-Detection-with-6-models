{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Model for Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading https://files.pythonhosted.org/packages/81/a7/4179e6ebfd654bd0eac0b9c06125b8b4c96a9d0a8ff9e9507eb2a26d2d7e/imblearn-0.0-py2.py3-none-any.whl\n",
      "Collecting imbalanced-learn (from imblearn)\n",
      "  Downloading https://files.pythonhosted.org/packages/c8/73/36a13185c2acff44d601dc6107b5347e075561a49e15ddd4e69988414c3e/imbalanced_learn-0.6.2-py3-none-any.whl (163kB)\n",
      "Requirement already satisfied: numpy>=1.11 in c:\\users\\bhave\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.16.2)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in c:\\users\\bhave\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.22)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\bhave\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17 in c:\\users\\bhave\\anaconda3\\lib\\site-packages (from imbalanced-learn->imblearn) (1.2.1)\n",
      "Installing collected packages: imbalanced-learn, imblearn\n",
      "Successfully installed imbalanced-learn-0.6.2 imblearn-0.0\n"
     ]
    }
   ],
   "source": [
    "#installing iblearn\n",
    "!pip install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd        #for dataframe data structure\n",
    "import numpy as np         # for numpy arrays and scientific computations\n",
    "\n",
    "import matplotlib.pyplot as plt      #for data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression    #for LogisticRegression Model\n",
    "from sklearn import metrics                            #for evaluation metrics\n",
    "                                                       \n",
    "import seaborn as sns                                  #for visualization\n",
    "from sklearn.preprocessing import StandardScaler       #for Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE               #for SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "df=pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "data=df.sample(frac=1,random_state=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the Amount column\n",
    "df['normAmount'] = StandardScaler().fit_transform(np.array(df['Amount']).reshape(-1, 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 32)\n"
     ]
    }
   ],
   "source": [
    "data=df.sample(frac=1,random_state=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating predictor and target variables\n",
    "X=data.copy()\n",
    "X.drop(['Class'],axis=1,inplace=True)\n",
    "y=data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (227845, 31)\n",
      "Number transactions y_train dataset:  (227845,)\n",
      "Number transactions X_test dataset:  (56962, 31)\n",
      "Number transactions y_test dataset:  (56962,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting dataset into Trainset and Testset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape) \n",
    "print(\"Number transactions y_train dataset: \", y_train.shape) \n",
    "print(\"Number transactions X_test dataset: \", X_test.shape) \n",
    "print(\"Number transactions y_test dataset: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.Selecting the Best Sampling Technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score :  0.9991046662687406\n",
      "Log Loss :  0.030924026327841993\n",
      "F1- Score :  0.9990836074436179\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.77      0.70      0.73       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.88      0.85      0.87     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.01,solver='liblinear')\n",
    "lr.fit(X_train,y_train)\n",
    "yhat=lr.predict(X_test)\n",
    "yhat_prob=lr.predict_proba(X_test)\n",
    "\n",
    "T1=metrics.accuracy_score(y_test,yhat)\n",
    "L1=metrics.log_loss(y_test,yhat)\n",
    "F1=metrics.f1_score(y_test,yhat,average='weighted')\n",
    "C1=metrics.classification_report(y_test,yhat)\n",
    "print(\"Test Accuracy score : \",T1)\n",
    "print(\"Log Loss : \",L1)\n",
    "print(\"F1- Score : \",F1)\n",
    "print(\"Classification Report : \",C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "one=pd.DataFrame([T1,L1,F1,1.00,0.70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset creditcasrd.csv that we are dealing with is imbalanced i.e. very less cases of one type and huge of other. These creates a bias in the modeling classifier and leads to mislearning. One approach to addresse imbalanced datasets is to oversample the minority class. The simplest approach involves duplicating examples in the minority class, although these examples don’t add any new information to the model. Instead, new examples can be synthesized from the existing examples. This is a type of data augmentation for the minority class and is referred to as the Synthetic Minority Oversampling Technique, or SMOTE for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling - counts of label '1': 392\n",
      "Before OverSampling - counts of label '0': 227453 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling - counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling - counts of label '0': {} \\n\".format(sum(y_train == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling - the shape of train_X: (454906, 31)\n",
      "After OverSampling - the shape of train_y: (454906,) \n",
      "\n",
      "After OverSampling - counts of label '1': 227453\n",
      "After OverSampling - counts of label '0': 227453\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "  \n",
    "print('After OverSampling - the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling - the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling - counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling - counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score :  0.9821108809381693\n",
      "Log Loss :  0.6178824468983024\n",
      "F1- Score :  0.9894841680608832\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56862\n",
      "           1       0.08      0.90      0.15       100\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.54      0.94      0.57     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.01,solver='liblinear')\n",
    "lr.fit(X_train_res,y_train_res)\n",
    "yhat=lr.predict(X_test)\n",
    "yhat_prob=lr.predict_proba(X_test)\n",
    "\n",
    "T2=metrics.accuracy_score(y_test,yhat)\n",
    "L2=metrics.log_loss(y_test,yhat)\n",
    "F2=metrics.f1_score(y_test,yhat,average='weighted')\n",
    "C2=metrics.classification_report(y_test,yhat)\n",
    "print(\"Test Accuracy score : \",T2)\n",
    "print(\"Log Loss : \",L2)\n",
    "print(\"F1- Score : \",F2)\n",
    "print(\"Classification Report : \",C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "two=pd.DataFrame([T2,L2,F2,0.98,0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. NearMiss Undersampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset creditcasrd.csv that we are dealing with is imbalanced i.e. very less cases of one type and huge of other. These creates a bias in the modeling classifier and leads to mislearning. Another approach to addresse imbalanced datasets is to undersample the majority class. TUndersampling refers to a group of techniques designed to balance the class distribution for a classification dataset that has a skewed class distribution.Undersampling techniques remove examples from the training dataset that belong to the majority class in order to better balance the class distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Undersampling - counts of label '1': 392\n",
      "Before Undersampling - counts of label '0': 227453 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before Undersampling - counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before Undersampling - counts of label '0': {} \\n\".format(sum(y_train == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Undersampling - the shape of train_X: (784, 31)\n",
      "After Undersampling - the shape of train_y: (784,) \n",
      "\n",
      "After Undersampling - counts of label '1': 392\n",
      "After Undersampling - counts of label '0': 392\n"
     ]
    }
   ],
   "source": [
    "# apply near miss \n",
    "from imblearn.under_sampling import NearMiss \n",
    "nr = NearMiss() \n",
    "  \n",
    "X_train_miss, y_train_miss = nr.fit_sample(X_train, y_train.ravel()) \n",
    "  \n",
    "print('After Undersampling - the shape of train_X: {}'.format(X_train_miss.shape)) \n",
    "print('After Undersampling - the shape of train_y: {} \\n'.format(y_train_miss.shape)) \n",
    "  \n",
    "print(\"After Undersampling - counts of label '1': {}\".format(sum(y_train_miss == 1))) \n",
    "print(\"After Undersampling - counts of label '0': {}\".format(sum(y_train_miss == 0))) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score :  0.7979003546223798\n",
      "Log Loss :  6.980435989358537\n",
      "F1- Score :  0.8858530183055309\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89     56862\n",
      "           1       0.01      0.95      0.02       100\n",
      "\n",
      "    accuracy                           0.80     56962\n",
      "   macro avg       0.50      0.87      0.45     56962\n",
      "weighted avg       1.00      0.80      0.89     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr=LogisticRegression(C=0.01,solver='liblinear')\n",
    "lr.fit(X_train_miss,y_train_miss)\n",
    "yhat=lr.predict(X_test)\n",
    "yhat_prob=lr.predict_proba(X_test)\n",
    "\n",
    "T3=metrics.accuracy_score(y_test,yhat)\n",
    "L3=metrics.log_loss(y_test,yhat)\n",
    "F3=metrics.f1_score(y_test,yhat,average='weighted')\n",
    "C3=metrics.classification_report(y_test,yhat)\n",
    "print(\"Test Accuracy score : \",T3)\n",
    "print(\"Log Loss : \",L3)\n",
    "print(\"F1- Score : \",F3)\n",
    "print(\"Classification Report : \",C3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "three=pd.DataFrame([T3,L3,F3,0.80,0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train_res\n",
    "y_train=y_train_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the OverSmapling Techinique gives the best model acuuracy.\n",
    "Therefore, moving ahead using Oversampling datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Selecting the Best Solver "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.liblinear solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(C=0.01,solver='liblinear')\n",
    "lr.fit(X_train,y_train)\n",
    "yhat=lr.predict(X_test)\n",
    "yhat_prob=lr.predict_proba(X_test)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score :  0.9821108809381693\n",
      "Log Loss :  0.6178824468983024\n",
      "F1- Score :  0.9894841680608832\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56862\n",
      "           1       0.08      0.90      0.15       100\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.54      0.94      0.57     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T4=metrics.accuracy_score(y_test,yhat)\n",
    "L4=metrics.log_loss(y_test,yhat)\n",
    "F4=metrics.f1_score(y_test,yhat,average='weighted')\n",
    "C4=metrics.classification_report(y_test,yhat)\n",
    "print(\"Test Accuracy score : \",T4)\n",
    "print(\"Log Loss : \",L4)\n",
    "print(\"F1- Score : \",F4)\n",
    "print(\"Classification Report : \",C4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "four=pd.DataFrame([T4,L4,F4,0.98,0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. saga solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhave\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='saga', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(C=0.01,solver='saga')\n",
    "lr.fit(X_train,y_train)\n",
    "yhat=lr.predict(X_test)\n",
    "yhat_prob=lr.predict_proba(X_test)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score :  0.9249148555177136\n",
      "Log Loss :  2.5934085203212605\n",
      "F1- Score :  0.9593113054959429\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96     56862\n",
      "           1       0.01      0.62      0.03       100\n",
      "\n",
      "    accuracy                           0.92     56962\n",
      "   macro avg       0.51      0.77      0.49     56962\n",
      "weighted avg       1.00      0.92      0.96     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T5=metrics.accuracy_score(y_test,yhat)\n",
    "L5=metrics.log_loss(y_test,yhat)\n",
    "F5=metrics.f1_score(y_test,yhat,average='weighted')\n",
    "C5=metrics.classification_report(y_test,yhat)\n",
    "print(\"Test Accuracy score : \",T5)\n",
    "print(\"Log Loss : \",L5)\n",
    "print(\"F1- Score : \",F5)\n",
    "print(\"Classification Report : \",C5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "five=pd.DataFrame([T5,L5,F5,0.93,0.62])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. lbfgs solver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr=LogisticRegression(C=0.01,solver='lbfgs')\n",
    "lr.fit(X_train,y_train)\n",
    "yhat=lr.predict(X_test)\n",
    "yhat_prob=lr.predict_proba(X_test)\n",
    "lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score :  0.9798988799550578\n",
      "Log Loss :  0.6942840229496164\n",
      "F1- Score :  0.9883319570806999\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56862\n",
      "           1       0.07      0.90      0.14       100\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.54      0.94      0.56     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T6=metrics.accuracy_score(y_test,yhat)\n",
    "L6=metrics.log_loss(y_test,yhat)\n",
    "F6=metrics.f1_score(y_test,yhat,average='weighted')\n",
    "C6=metrics.classification_report(y_test,yhat)\n",
    "print(\"Test Accuracy score : \",T6)\n",
    "print(\"Log Loss : \",L6)\n",
    "print(\"F1- Score : \",F6)\n",
    "print(\"Classification Report : \",C6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "six=pd.DataFrame([T6,L6,F6,0.98,0.90])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_solver='liblinear'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that that the liblinear solver proves to be the best among others.Therefore moving ahead ushing liblinear as solver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Selecting Best value of C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Using GridSearchCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "par=[{'C':[0.001,0.01,0.1,1,10,100,1000]}]\n",
    "lr=LogisticRegression(solver=best_solver)\n",
    "Grid=GridSearchCV(lr,par,cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                          fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='liblinear',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid=[{'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96801757, 0.96802197, 0.96802856, 0.96802856, 0.96802856,\n",
       "       0.96802856, 0.96802856])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Grid.cv_results_['mean_test_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best value according to the GridSearchCV() is C=0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Using mean and standard accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.98260244, 0.98211088, 0.98209333, 0.98209333, 0.98209333,\n",
       "       0.98209333, 0.98209333])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best value of C\n",
    "C = [0.001,0.01,0.1,1,10,100,1000]\n",
    "\n",
    "mean_acc = np.zeros(len(C))\n",
    "std_acc = np.zeros(len(C))\n",
    "\n",
    "for n,c in enumerate(C):\n",
    "    #Train Model and Predict  \n",
    "    lr = LogisticRegression(C=c,solver=best_solver)\n",
    "    lr.fit(X_train,y_train)\n",
    "    yhat=lr.predict(X_test)\n",
    "    mean_acc[n] = metrics.accuracy_score(y_test, yhat)\n",
    "        \n",
    "    std_acc[n]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best of C : 0.001\n"
     ]
    }
   ],
   "source": [
    "print ('Best of C : {}'.format(C[mean_acc.argmax()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(C,mean_acc,'b')\n",
    "plt.fill_between(C,mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('C')\n",
    "#plt.xlim(0.001,)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_c=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that that the value C = 0.001 proves to be the best among others.Therefore moving ahead using C as 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling using the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy score :  0.982602436712194\n",
      "Log Loss :  0.6009043188868992\n",
      "F1- Score :  0.9897406052823171\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     56862\n",
      "           1       0.08      0.90      0.15       100\n",
      "\n",
      "    accuracy                           0.98     56962\n",
      "   macro avg       0.54      0.94      0.57     56962\n",
      "weighted avg       1.00      0.98      0.99     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_lr= LogisticRegression(C=best_c, solver=best_solver)\n",
    "best_lr.fit(X_train,y_train)\n",
    "yhat=best_lr.predict(X_test)\n",
    "yhat_prob=best_lr.predict_proba(X_test)\n",
    "\n",
    "T7=metrics.accuracy_score(y_test,yhat)\n",
    "L7=metrics.log_loss(y_test,yhat)\n",
    "F7=metrics.f1_score(y_test,yhat,average='weighted')\n",
    "C7=metrics.classification_report(y_test,yhat)\n",
    "print(\"Test Accuracy score : \",T7)\n",
    "print(\"Log Loss : \",L7)\n",
    "print(\"F1- Score : \",F7)\n",
    "print(\"Classification Report : \",C7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "seven=pd.DataFrame([T7,L7,F7,0.98,0.90])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================    Logistic Regression Analysis Report   ===============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Sampling</th>\n",
       "      <th>SMOTE Oversampling</th>\n",
       "      <th>NearMiss Undersampling</th>\n",
       "      <th>liblinear solver</th>\n",
       "      <th>saga solver</th>\n",
       "      <th>lbfgs solver</th>\n",
       "      <th>BEST MODEL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Criteria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.982111</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.982111</td>\n",
       "      <td>0.924915</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.982602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Loss</th>\n",
       "      <td>0.030924</td>\n",
       "      <td>0.617882</td>\n",
       "      <td>6.980436</td>\n",
       "      <td>0.617882</td>\n",
       "      <td>2.593409</td>\n",
       "      <td>0.694284</td>\n",
       "      <td>0.600904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.989484</td>\n",
       "      <td>0.885853</td>\n",
       "      <td>0.989484</td>\n",
       "      <td>0.959311</td>\n",
       "      <td>0.988332</td>\n",
       "      <td>0.989741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class0 Recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class1 Recall</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                No Sampling  SMOTE Oversampling  NearMiss Undersampling  \\\n",
       "Criteria                                                                  \n",
       "Accuracy Score     0.999105            0.982111                0.797900   \n",
       "Log Loss           0.030924            0.617882                6.980436   \n",
       "F1-Score           0.999084            0.989484                0.885853   \n",
       "Class0 Recall      1.000000            0.980000                0.800000   \n",
       "Class1 Recall      0.700000            0.900000                0.950000   \n",
       "\n",
       "                liblinear solver  saga solver  lbfgs solver  BEST MODEL  \n",
       "Criteria                                                                 \n",
       "Accuracy Score          0.982111     0.924915      0.979899    0.982602  \n",
       "Log Loss                0.617882     2.593409      0.694284    0.600904  \n",
       "F1-Score                0.989484     0.959311      0.988332    0.989741  \n",
       "Class0 Recall           0.980000     0.930000      0.980000    0.980000  \n",
       "Class1 Recall           0.900000     0.620000      0.900000    0.900000  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"===============================    Logistic Regression Analysis Report   ===============================\")\n",
    "res=pd.concat([one,two,three,four,five,six,seven],axis=1)\n",
    "rows=pd.DataFrame(['Accuracy Score','Log Loss','F1-Score','Class0 Recall','Class1 Recall'])\n",
    "res=pd.concat([res,rows],axis=1)\n",
    "res.columns=['No Sampling','SMOTE Oversampling','NearMiss Undersampling','liblinear solver','saga solver','lbfgs solver','BEST MODEL','Criteria']\n",
    "res.set_index(\"Criteria\", inplace = True) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Sampling</th>\n",
       "      <th>SMOTE Oversampling</th>\n",
       "      <th>NearMiss Undersampling</th>\n",
       "      <th>liblinear solver</th>\n",
       "      <th>saga solver</th>\n",
       "      <th>lbfgs solver</th>\n",
       "      <th>Best Model</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Criteria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.999105</td>\n",
       "      <td>0.982111</td>\n",
       "      <td>0.797900</td>\n",
       "      <td>0.982111</td>\n",
       "      <td>0.924915</td>\n",
       "      <td>0.979899</td>\n",
       "      <td>0.982602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Loss</th>\n",
       "      <td>0.030924</td>\n",
       "      <td>0.617882</td>\n",
       "      <td>6.980436</td>\n",
       "      <td>0.617882</td>\n",
       "      <td>2.593409</td>\n",
       "      <td>0.694284</td>\n",
       "      <td>0.600904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.999084</td>\n",
       "      <td>0.989484</td>\n",
       "      <td>0.885853</td>\n",
       "      <td>0.989484</td>\n",
       "      <td>0.959311</td>\n",
       "      <td>0.988332</td>\n",
       "      <td>0.989741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class0 Recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class1 Recall</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                No Sampling  SMOTE Oversampling  NearMiss Undersampling  \\\n",
       "Criteria                                                                  \n",
       "Accuracy Score     0.999105            0.982111                0.797900   \n",
       "Log Loss           0.030924            0.617882                6.980436   \n",
       "F1-Score           0.999084            0.989484                0.885853   \n",
       "Class0 Recall      1.000000            0.980000                0.800000   \n",
       "Class1 Recall      0.700000            0.900000                0.950000   \n",
       "\n",
       "                liblinear solver  saga solver  lbfgs solver  Best Model  \n",
       "Criteria                                                                 \n",
       "Accuracy Score          0.982111     0.924915      0.979899    0.982602  \n",
       "Log Loss                0.617882     2.593409      0.694284    0.600904  \n",
       "F1-Score                0.989484     0.959311      0.988332    0.989741  \n",
       "Class0 Recall           0.980000     0.930000      0.980000    0.980000  \n",
       "Class1 Recall           0.900000     0.620000      0.900000    0.900000  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
