{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Isolation Forest Model for Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd        #for dataframe data structure\n",
    "import numpy as np         # for numpy arrays and scientific computations\n",
    "\n",
    "import matplotlib.pyplot as plt      #for data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.ensemble import IsolationForest       #for Isolation Forest Model\n",
    "from sklearn import metrics                            #for evaluation metrics\n",
    "                                                       \n",
    "import seaborn as sns                                  #for visualization\n",
    "from sklearn.preprocessing import StandardScaler       #for Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE               #for SMOTE Oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "df=pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "data=df.sample(frac=1,random_state=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017304750013189597\n",
      "fraud cases: 492\n",
      "valid cases: 284315\n"
     ]
    }
   ],
   "source": [
    "fraud = data[data['Class'] == 1]\n",
    "valid = data[data['Class'] == 0]\n",
    "\n",
    "outlier_frac = len(fraud) / float(len(valid))\n",
    "print(outlier_frac)\n",
    "\n",
    "print(\"fraud cases: {}\".format(len(fraud)))\n",
    "print(\"valid cases: {}\".format(len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating predictor and target variables\n",
    "X=data.copy()\n",
    "X.drop(['Class'],axis=1,inplace=True)\n",
    "y=data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (227845, 30)\n",
      "Number transactions y_train dataset:  (227845,)\n",
      "Number transactions X_test dataset:  (56962, 30)\n",
      "Number transactions y_test dataset:  (56962,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting dataset into Trainset and Testset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape) \n",
    "print(\"Number transactions y_train dataset: \", y_train.shape) \n",
    "print(\"Number transactions X_test dataset: \", X_test.shape) \n",
    "print(\"Number transactions y_test dataset: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best Sampling technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before SMOTE OverSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a random state\n",
    "state = 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='new', bootstrap=False,\n",
       "                contamination=0.0017304750013189597, max_features=1.0,\n",
       "                max_samples=227845, n_estimators=100, n_jobs=None,\n",
       "                random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isf=IsolationForest(max_samples=len(X_train), contamination = outlier_frac, random_state = state, behaviour = \"new\")\n",
    "isf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhave\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:248: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='new', bootstrap=False,\n",
       "                contamination=0.0017304750013189597, max_features=1.0,\n",
       "                max_samples=227845, n_estimators=100, n_jobs=None,\n",
       "                random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isf.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_pred = isf.decision_function(X_test)\n",
    "y_pred = isf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.19082215, 0.19030468, 0.19023666, 0.15133028, 0.1680755 ,\n",
       "       0.1786962 , 0.19176756, 0.18135336, 0.18857889, 0.18366131])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    56859\n",
       "-1      103\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_pred)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Errors :  115\n",
      "Test Accuracy score :  0.9979811102138267\n",
      "Log Loss :  0.06973081109622496\n",
      "F1- Score :  0.9979960014891391\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.43      0.44      0.43       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.71      0.72      0.72     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "E1=(y_pred != y_test).sum()\n",
    "T1=metrics.accuracy_score(y_test,y_pred)\n",
    "L1=metrics.log_loss(y_test,y_pred)\n",
    "F1=metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "C1=metrics.classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Number of Errors : \",E1)\n",
    "print(\"Test Accuracy score : \",T1)\n",
    "print(\"Log Loss : \",L1)\n",
    "print(\"F1- Score : \",F1)\n",
    "print(\"Classification Report : \",C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "one=pd.DataFrame([E1,T1,L1,F1,1.00,0.44])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After SMOTE OverSampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset creditcasrd.csv that we are dealing with is imbalanced i.e. very less cases of one type and huge of other. These creates a bias in the modeling classifier and leads to mislearning. One approach to addresse imbalanced datasets is to oversample the minority class. The simplest approach involves duplicating examples in the minority class, although these examples donâ€™t add any new information to the model. Instead, new examples can be synthesized from the existing examples. This is a type of data augmentation for the minority class and is referred to as the Synthetic Minority Oversampling Technique, or SMOTE for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before OverSampling - counts of label '1': 392\n",
      "Before OverSampling - counts of label '0': 227453 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Before OverSampling - counts of label '1': {}\".format(sum(y_train == 1))) \n",
    "print(\"Before OverSampling - counts of label '0': {} \\n\".format(sum(y_train == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling - the shape of train_X: (454906, 30)\n",
      "After OverSampling - the shape of train_y: (454906,) \n",
      "\n",
      "After OverSampling - counts of label '1': 227453\n",
      "After OverSampling - counts of label '0': 227453\n"
     ]
    }
   ],
   "source": [
    "sm = SMOTE(random_state = 2) \n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train) \n",
    "  \n",
    "print('After OverSampling - the shape of train_X: {}'.format(X_train_res.shape)) \n",
    "print('After OverSampling - the shape of train_y: {} \\n'.format(y_train_res.shape)) \n",
    "  \n",
    "print(\"After OverSampling - counts of label '1': {}\".format(sum(y_train_res == 1))) \n",
    "print(\"After OverSampling - counts of label '0': {}\".format(sum(y_train_res == 0))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsolationForest(behaviour='new', bootstrap=False,\n",
       "                contamination=0.0017304750013189597, max_features=1.0,\n",
       "                max_samples=454906, n_estimators=100, n_jobs=None,\n",
       "                random_state=1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isf1=IsolationForest(max_samples=len(X_train_res), contamination = outlier_frac, random_state = state, behaviour = \"new\")\n",
    "isf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhave\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:248: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " 1    56909\n",
       "-1       53\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isf1.fit(X_train_res)\n",
    "score_pred = isf1.decision_function(X_test)\n",
    "y_pred = isf1.predict(X_test)\n",
    "pd.DataFrame(y_pred)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Errors :  147\n",
      "Test Accuracy score :  0.9974193321863699\n",
      "Log Loss :  0.08913381043368275\n",
      "F1- Score :  0.9970234881544296\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.06      0.03      0.04       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.53      0.51      0.52     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n",
      "Number of Errors :  147\n",
      "Test Accuracy score :  0.9974193321863699\n",
      "Log Loss :  0.08913381043368275\n",
      "F1- Score :  0.9970234881544296\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.06      0.03      0.04       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.53      0.51      0.52     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "E2=(y_pred != y_test).sum()\n",
    "T2=metrics.accuracy_score(y_test,y_pred)\n",
    "L2=metrics.log_loss(y_test,y_pred)\n",
    "F2=metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "C2=metrics.classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Number of Errors : \",E2)\n",
    "print(\"Test Accuracy score : \",T2)\n",
    "print(\"Log Loss : \",L2)\n",
    "print(\"F1- Score : \",F2)\n",
    "print(\"Classification Report : \",C2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "two=pd.DataFrame([E2,T2,L2,F2,1.00,0.03])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case OutSampling doesn't prove to be effecting. Therefore the best model will undergo no sampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhave\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_iforest.py:248: FutureWarning: 'behaviour' is deprecated in 0.22 and will be removed in 0.24. You should not pass or set this parameter.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Errors :  115\n",
      "Test Accuracy score :  0.9979811102138267\n",
      "Log Loss :  0.06973081109622496\n",
      "F1- Score :  0.9979960014891391\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.43      0.44      0.43       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.71      0.72      0.72     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "isf_best=IsolationForest(max_samples=len(X_train), contamination = outlier_frac, random_state = state, behaviour = \"new\")\n",
    "isf_best.fit(X_train)\n",
    "score_pred = isf_best.decision_function(X_test)\n",
    "y_pred = isf_best.predict(X_test)\n",
    "pd.DataFrame(y_pred)[0].value_counts()\n",
    "y_pred[y_pred == 1] = 0\n",
    "y_pred[y_pred == -1] = 1\n",
    "\n",
    "E3=(y_pred != y_test).sum()\n",
    "T3=metrics.accuracy_score(y_test,y_pred)\n",
    "L3=metrics.log_loss(y_test,y_pred)\n",
    "F3=metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "C3=metrics.classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Number of Errors : \",E3)\n",
    "print(\"Test Accuracy score : \",T3)\n",
    "print(\"Log Loss : \",L3)\n",
    "print(\"F1- Score : \",F3)\n",
    "print(\"Classification Report : \",C3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "three=pd.DataFrame([E3,T3,L3,F3,1.00,0.44])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================    Isolation Forest Analysis Report   ===============================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>No Sampling</th>\n",
       "      <th>SMOTE Oversampling</th>\n",
       "      <th>BEST MODEL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Criteria</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No.of Error</th>\n",
       "      <td>147.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>115.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.997419</td>\n",
       "      <td>0.997419</td>\n",
       "      <td>0.997981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Loss</th>\n",
       "      <td>0.089134</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>0.069731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.997023</td>\n",
       "      <td>0.997023</td>\n",
       "      <td>0.997996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class0 Recall</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class1 Recall</th>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.440000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                No Sampling  SMOTE Oversampling  BEST MODEL\n",
       "Criteria                                                   \n",
       "No.of Error      147.000000          147.000000  115.000000\n",
       "Accuracy Score     0.997419            0.997419    0.997981\n",
       "Log Loss           0.089134            0.089134    0.069731\n",
       "F1-Score           0.997023            0.997023    0.997996\n",
       "Class0 Recall      1.000000            1.000000    1.000000\n",
       "Class1 Recall      0.030000            0.030000    0.440000"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"===============================    Isolation Forest Analysis Report   ===============================\")\n",
    "res=pd.concat([one,two,three],axis=1)\n",
    "rows=pd.DataFrame(['No.of Error','Accuracy Score','Log Loss','F1-Score','Class0 Recall','Class1 Recall'])\n",
    "res=pd.concat([res,rows],axis=1)\n",
    "res.columns=['No Sampling','SMOTE Oversampling','BEST MODEL','Criteria']\n",
    "res.set_index(\"Criteria\", inplace = True) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
