{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Outlier Factor for Credit Card Fraud Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd        #for dataframe data structure\n",
    "import numpy as np         # for numpy arrays and scientific computations\n",
    "\n",
    "import matplotlib.pyplot as plt      #for data visualization\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor       #for Local Outlier Factor Model\n",
    "from sklearn import metrics                            #for evaluation metrics\n",
    "                                                       \n",
    "import seaborn as sns                                  #for visualization\n",
    "from sklearn.preprocessing import StandardScaler       #for Data Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing dataset\n",
    "df=pd.read_csv(\"creditcard.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "data=df.sample(frac=1,random_state=1)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017304750013189597\n",
      "fraud cases: 492\n",
      "valid cases: 284315\n"
     ]
    }
   ],
   "source": [
    "fraud = data[data['Class'] == 1]\n",
    "valid = data[data['Class'] == 0]\n",
    "\n",
    "outlier_frac = len(fraud) / float(len(valid))\n",
    "print(outlier_frac)\n",
    "\n",
    "print(\"fraud cases: {}\".format(len(fraud)))\n",
    "print(\"valid cases: {}\".format(len(valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating predictor and target variables\n",
    "X=data.copy()\n",
    "X.drop(['Class'],axis=1,inplace=True)\n",
    "y=data['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number transactions X_train dataset:  (227845, 30)\n",
      "Number transactions y_train dataset:  (227845,)\n",
      "Number transactions X_test dataset:  (56962, 30)\n",
      "Number transactions y_test dataset:  (56962,)\n"
     ]
    }
   ],
   "source": [
    "#Splitting dataset into Trainset and Testset\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape) \n",
    "print(\"Number transactions y_train dataset: \", y_train.shape) \n",
    "print(\"Number transactions X_test dataset: \", X_test.shape) \n",
    "print(\"Number transactions y_test dataset: \", y_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof=LocalOutlierFactor(n_neighbors= 20,  contamination = outlier_frac,novelty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof.fit(X_train)\n",
    "scores_pred = lof.negative_outlier_factor_\n",
    "y_pred=lof.predict(X_test)\n",
    "## The  prediction value for these models by default give -1 and +1 which needs to be changed to 0 and  1\n",
    "y_pred[y_pred == 1] =0\n",
    "y_pred[y_pred == -1] =1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.97906414, -1.23295533, -1.05882661, -1.00185324, -1.06958944,\n",
       "       -1.2796321 , -1.10686473, -1.04731905, -1.21170617, -1.03007765])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Errors :  184\n",
      "Test Accuracy score :  0.9967697763421228\n",
      "Log Loss :  0.11156922195208928\n",
      "F1- Score :  0.9967199096375808\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.05      0.05      0.05       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.53      0.52      0.52     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "E1=(y_pred != y_test).sum()\n",
    "T1=metrics.accuracy_score(y_test,y_pred)\n",
    "L1=metrics.log_loss(y_test,y_pred)\n",
    "F1=metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "C1=metrics.classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Number of Errors : \",E1)\n",
    "print(\"Test Accuracy score : \",T1)\n",
    "print(\"Log Loss : \",L1)\n",
    "print(\"F1- Score : \",F1)\n",
    "print(\"Classification Report : \",C1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "one=pd.DataFrame([E1,T1,L1,F1,1.00,0.05])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting the best value of n_neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99638355, 0.99692778, 0.99713844, 0.99708578, 0.99703311,\n",
       "       0.99685755, 0.99685755, 0.99694533, 0.99691022, 0.99687511,\n",
       "       0.99682244, 0.99682244, 0.99676978, 0.99675222, 0.99673467,\n",
       "       0.99662933, 0.99671711, 0.99666444, 0.99673467, 0.99676978,\n",
       "       0.99680489, 0.99685755, 0.99680489, 0.99675222, 0.99671711,\n",
       "       0.99676978, 0.99671711, 0.99675222, 0.99682244, 0.99678733,\n",
       "       0.99680489, 0.99676978, 0.99676978, 0.99676978, 0.99671711,\n",
       "       0.99662933, 0.99664689, 0.99664689, 0.99669955, 0.        ])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the best value of C\n",
    "ns = 40\n",
    "\n",
    "mean_acc = np.zeros(ns)\n",
    "std_acc = np.zeros(ns)\n",
    "\n",
    "for i in range(1,ns):\n",
    "    #Train Model and Predict  \n",
    "    lof=LocalOutlierFactor(n_neighbors=i,  contamination = outlier_frac,novelty=True)\n",
    "    lof.fit(X_train)\n",
    "    y_pred=lof.predict(X_test)\n",
    "    y_pred[y_pred == 1] =0\n",
    "    y_pred[y_pred == -1] =1    \n",
    "    mean_acc[i-1] = metrics.accuracy_score(y_test, y_pred)\n",
    "        \n",
    "    std_acc[i-1]=np.std(y_test==y_pred)/np.sqrt(y_pred.shape[0])\n",
    "\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,ns+1),mean_acc,'b')\n",
    "plt.fill_between(range(1,ns+1),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\n",
    "plt.legend(('Accuracy ', '+/- 3xstd'))\n",
    "plt.ylabel('Accuracy ')\n",
    "plt.xlabel('n_neighbours')\n",
    "#plt.xlim(0.001,)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_n=35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph we can conclude that all values from 1 to 37 result in the same accuracy. Therefore let us consider n_neighbors=35 as our best value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lof=LocalOutlierFactor(n_neighbors= best_n,  contamination = outlier_frac,novelty=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_lof.fit(X_train)\n",
    "scores_pred = best_lof.negative_outlier_factor_\n",
    "y_pred=best_lof.predict(X_test)\n",
    "## The  prediction value for these models by default give -1 and +1 which needs to be changed to 0 and  1\n",
    "y_pred[y_pred == 1] =0\n",
    "y_pred[y_pred == -1] =1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Errors :  187\n",
      "Test Accuracy score :  0.9967171096520487\n",
      "Log Loss :  0.11338825094663478\n",
      "F1- Score :  0.9966217345600386\n",
      "Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     56862\n",
      "           1       0.01      0.01      0.01       100\n",
      "\n",
      "    accuracy                           1.00     56962\n",
      "   macro avg       0.50      0.50      0.50     56962\n",
      "weighted avg       1.00      1.00      1.00     56962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "E2=(y_pred != y_test).sum()\n",
    "T2=metrics.accuracy_score(y_test,y_pred)\n",
    "L2=metrics.log_loss(y_test,y_pred)\n",
    "F2=metrics.f1_score(y_test,y_pred,average='weighted')\n",
    "C2=metrics.classification_report(y_test,y_pred)\n",
    "\n",
    "print(\"Number of Errors : \",E2)\n",
    "print(\"Test Accuracy score : \",T2)\n",
    "print(\"Log Loss : \",L2)\n",
    "print(\"F1- Score : \",F2)\n",
    "print(\"Classification Report : \",C2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving accuracy results\n",
    "two=pd.DataFrame([E2,T2,L2,F2,1.00,0.05,35])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================  Local Outlier Factor Analysis Report   ======================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BEST MODEL</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Criteria</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No.of Error</th>\n",
       "      <td>187.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy Score</th>\n",
       "      <td>0.996717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Log Loss</th>\n",
       "      <td>0.113388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.996622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class0 Recall</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Class1 Recall</th>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_neighbors</th>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                BEST MODEL\n",
       "Criteria                  \n",
       "No.of Error     187.000000\n",
       "Accuracy Score    0.996717\n",
       "Log Loss          0.113388\n",
       "F1-Score          0.996622\n",
       "Class0 Recall     1.000000\n",
       "Class1 Recall     0.050000\n",
       "n_neighbors      35.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=====================  Local Outlier Factor Analysis Report   ======================\")\n",
    "res=pd.concat([two],axis=1)\n",
    "rows=pd.DataFrame(['No.of Error','Accuracy Score','Log Loss','F1-Score','Class0 Recall','Class1 Recall','n_neighbors'])\n",
    "res=pd.concat([res,rows],axis=1)\n",
    "res.columns=['BEST MODEL','Criteria']\n",
    "res.set_index(\"Criteria\", inplace = True) \n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
